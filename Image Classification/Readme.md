# Image Classification with Multiple Models on Fashion MNIST

This project demonstrates image classification using multiple machine learning and deep learning models on the Fashion MNIST dataset.

## Dataset

The Fashion MNIST dataset consists of 70,000 grayscale images of 28x28 pixels, divided into 60,000 training images and 10,000 testing images. Each image belongs to one of the 10 classes.

## Topic Models

- Multi-Layer Perceptron (MLP): An MLP is a type of artificial neural network that consists of multiple layers of nodes, each layer fully connected to the next one. It is suitable for tasks where input data is in a fixed-size vector format.
- Support Vector Machine (SVM): SVM is a supervised learning algorithm that finds the hyperplane that best separates the classes in a feature space. It's effective in high-dimensional spaces and is used for classification tasks.
- K-Nearest Neighbors (KNN): KNN is a simple, instance-based learning algorithm that classifies new data points based on the majority class among the k-nearest neighbors. It is non-parametric and lazy learning.
- Convolutional Neural Network (CNN): CNNs are deep learning models designed to process structured grid data like images. They use convolutional layers to extract features and pooling layers to downsample the data.
- Random Forest: Random Forest is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of the classes for classification tasks. It reduces overfitting and improves accuracy.
- XGBoost (Gradient Boosting Machine): XGBoost is an optimized gradient boosting algorithm that is efficient and scalable. It uses ensemble techniques to improve predictive accuracy by combining multiple weak models.


## Visualizations

- **Image to Label Mapping**
- **Accuracy & Loss vs Epochs**
- **Accuracy between Models**
